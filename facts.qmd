---
title: "Mini-Project 04 - Just the Fact(-Check)s, Ma'am!"
editor:
    mode: source
format:
    html:
        toc: true
        code-fold: true
        crossref:
            fig-title: "Visual" 


---

## Introduction

The labor market is one of the most closely monitored indicators of economic health, and official employment statistics play a critical role in shaping policy decisions, business strategies, and public perception. Among these, the Current Employment Statistics (CES) program is published by the U.S. Bureau of Labor Statistics (BLS) and provides monthly estimates of nonfarm payroll employment, hours, and earnings. 

In this for this project, I will web scrape, conduct some statistical inference, and examine CES employment data and its revisions to look at some claims and determine how reliable they actually are.

## Data Acquisition and Preparation

To aquire this data, I had to pull and tidy BLS employment data and its monthly revisions. I could pull the data from the xlsx file available to download, but writing code to do so for every revision year would be a hassle. So instead, I decided to web scrape the data. First, I checked the web developer tools, and found the POST request required for the specific table. I sent that request to the BLS endpoint to download the CES000000001 series (total nonfarm employment) and cleaned the table. Next, I scraped the BLS CES revision page, and wrote a function to extract from every year and bind every year from 1979-2025 into one large table. This leaves two tables to look at the revision amount and the employment amount every year.


```{r setup}
#| warning: false
#| message: false
#| eval: true
#| output: false

library(httr2)
library(rvest)
library(dplyr)
library(tidyverse)
library(lubridate)
library(stringr)
library(purrr)
library(scales)
library(cowplot)
library(infer)


# 1. Make POST request
req <- request("https://data.bls.gov/pdq/SurveyOutputServlet") |>
  req_body_form(
    request_action = "get_data",
    reformat = "true",
    from_results_page = "true",
    from_year = "1979",
    to_year = "2025",
    Gx = "17",
    Go = "8",
    initial_request = "false",
    data_tool = "surveyoutput",
    series_id = "CES0000000001",
    original_annualAveragesRequested = "false"
  )

resp <- req_perform(req)

# 2. Parse HTML
html <- resp_body_html(resp)

# 3. Extract correct table by ID
data_table <- html |>
  html_element("#table0") |>
  html_table(fill = TRUE)




CES_EST <- data_table |>
  filter(str_detect(Year, "^[0-9]{4}$"))|>
  pivot_longer(
    cols = Jan:Dec,                
    names_to = "Month",            
    values_to = "employment"            
  )|>
  mutate(
    date = ym(paste(Year, Month)),
    year_month= paste(Year, Month),
    employment = as.numeric(str_replace_all(employment, "[^0-9]", ""))
    )

req2 <- 
  request("https://www.bls.gov/web/empsit/cesnaicsrev.htm")|>
  req_headers(
    "User-Agent" = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Referer" = "https://www.bls.gov/"
  )

resp2 <- req_perform(req2)
html2 <- resp_body_html(resp2)

extract_year_table <- function(year) {
  table_node <- html2 |> 
    html_element(paste0("#", year))
  if (inherits(table_node, "xml_missing")) return(NULL)
  
  tbl <- table_node |> 
    html_table(header = FALSE, fill = TRUE)|>
    slice(4:15) |>
    select(month = 1, original = 3, final = 5) |>
    mutate(
      month = str_sub(month, 1, 3),  
      date = ym(paste(year, month)),
      original = as.numeric(str_replace_all(original, "[^0-9-]", "")),
      final = as.numeric(str_replace_all(final, "[^0-9-]", "")),
      revision = final - original
    )
  
  return(tbl)
}

years <- 1979:2025
CES_REV <- map_dfr(years, extract_year_table)


```

## Exploratory Analysis

### Stats and Graphs

```{r}
CES<- CES_EST|>
  full_join(CES_REV|>
              select(date, original, final, revision),
            by = "date")|>
  mutate(
    Year = as.numeric(Year),
    monthly_change = employment - lag(employment),
    yoy_pct =  (employment / lag(employment, 12) - 1),
    # Revisions
    rev_abs = abs(revision),
    rev_dir = case_when(
      revision > 0 ~ "Upward",
      revision < 0 ~ "Downward",
      TRUE ~ "No change"
    ),
    
    # Grouping variables
    decade = paste0(floor(Year / 10) * 10, "s")
  )

# looking at changes with employment in total
emp_change <- CES |>
  summarize(
    mean_change = mean(monthly_change, na.rm = TRUE),
    median_change = median(monthly_change, na.rm = TRUE),
    pct_positive = mean(monthly_change > 0, na.rm = TRUE)
  )


ext_max <- CES |> filter(
  monthly_change == 
    max(monthly_change,na.rm = TRUE)) |> 
  slice(1)

ext_min <- CES |> 
  filter(monthly_change == min(monthly_change, na.rm = TRUE)) |> 
  slice(1)

fmt_date <- function(d) format(d, "%b %Y")

#revision stats
avg_rev_stats <- CES |>
  summarize(
    avg_abs_rev = mean(rev_abs, na.rm = TRUE),
    avg_pct_rev = mean(abs(revision / employment) * 100, na.rm = TRUE)
  )


```

Monthly changes average `r round((emp_change$mean_change),1)` thousand. Changes are positive in `r percent(emp_change$pct_positive, accuracy = 0.1)` months.

The largest increase was `r round((ext_max$monthly_change)/1000, 2)` million jobs in `r fmt_date(ext_max$date)`, and the largest decline was `r round((ext_min$monthly_change)/1000, 2)` million jobs in `r fmt_date(ext_min$date)`. Revision does not factor in a large amount of employment, with only `r percent(avg_rev_stats$avg_pct_rev, accuracy = 0.1)` of total employment changed by revision. On average, the revised job numbers change by `r round((avg_rev_stats$avg_abs_rev),1)` thousand jobs a month.


```{r}
#| label: fig-revpct

CES |>
  group_by(Year) |>
  summarize(
    avg_relative_revision = mean(abs(revision / final) * 100, na.rm = TRUE)
  )|>
  ggplot(aes(x = Year, y = avg_relative_revision)) +
  geom_line(color = "purple") +
  labs(title = "Average Relative Revision (% of Final Estimate) Over Time",
       y = "Avg Relative Revision (%)", x = "Year")+
  theme_cowplot()
  
```

This line chart shows spikes in relative revision magnitude during certain years, notably around 1990 and 2000. These peaks suggest periods of economic disruptions or possible methodological changes that made initial estimates less accurate. For example, the late 2000's great recession or the recession from July 1990 to March 1991 coincide with the same time period revisions on average spiked. Recent years are showing an increase of revisions similar to other years, indicating another possible economic disruption or change in methodology.

```{r}
#| label: fig-revmonth
CES |>
  group_by(Month) |>
  summarize(avg_abs_revision = mean(rev_abs, na.rm = TRUE)) |>
  mutate(Month = factor(Month, levels = month.abb))|>
  ggplot(aes(x = Month, y = avg_abs_revision)) +
  geom_col(fill = "purple") +
  labs(title = "Average Absolute Revision by Month",
       x = "Month", y = "Avg Revision (Thousands)") +
  theme_cowplot()

```

Looking at the systematic monthly revisions, there are some clear outliers. September has the highest average revision, while February and January are among the lowest. There could be some explanations, such as BLS revising data after adjusting with seasonal factors like [schools re-opening](https://www.nasra.org/content.asp?contentid=181) and hiring. That being said,

```{r}
#| label: fig-heatmap


CES |>
  group_by(decade, Month) |>
  summarize(avg_abs_revision = mean(rev_abs, na.rm = TRUE), .groups = "drop")|>
  mutate(Month = factor(Month, levels = month.abb))|>
  ggplot (aes(x = Month, y = decade, fill = avg_abs_revision)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Heatmap of Average CES Revision by Month and Decade",
       x = "Month", y = "Decade", fill = "Avg Revision")

```

The heat map backs up certain findings in the previous visualization, such as September often having a high number of revisions. However, some months have been more impactful in certain decades than others. For example, December has high average revisions in the 2020's than and 1970's compared to other decades. These two decades are likely why revisions overall are higher on average, especially as other decades seem to be more consistent with how many jobs are revised.

```{r}
#| warning: false
#| message: false

CES |>
  mutate(monthly_change_millions = monthly_change / 1000) |>
  ggplot(aes(x = date, y = monthly_change_millions)) +
  geom_line(alpha = 0.4, color = "darkgreen") +
  geom_smooth(span = 0.2, color = "purple", se = FALSE) +
  labs(title = "Smoothed Trend of Monthly Employment Changes (Full Scale)",
       x = "Year", y = "Change (Millions)") +
  theme_minimal()
```

```{r}
#| warning: false
#| message: false
#| label: fig-monthemp
CES |>
  ggplot(aes(x = date, y = monthly_change)) +
  geom_line(alpha = 0.4, color = "darkgreen") +
  geom_smooth(span = 0.2, color = "purple", se = FALSE) +
  coord_cartesian(ylim = c(-1000, 1000)) +  # Zoom in to ±1 million
  annotate("text", x = as.Date("2020-04-01"), y = -800,
           label = "COVID spike (~20M) excluded for clarity",
           color = "red", size = 2.5) +
  labs(title = "Smoothed Trend of Monthly Employment Changes (Zoomed)",
       x = "Year", y = "Change (Thousands)") +
  theme_minimal()


```

This visualization shows monthly employment changes over time, smoothed to highlight long-term trends. Most fluctuations are small, but the sharp drop in 2020 reflects the COVID-19 pandemic, followed by a rapid rebound. This makes the graph hard to read fluctuations, so a second graph is provided to show the smaller changes in the graph. Outside of this anomaly, employment changes remain relatively stable, suggesting that job changes are tied to major economic shocks, and that these shocks are often cyclicle raising in jobs created a few years after many are lost.

```{r}
#| label: fig-scatter
#| warning: false
#| message: false
CES |>
  ggplot(aes(x = employment, y = rev_abs)) +
  geom_point(alpha = 0.4, color = "purple") +
  geom_smooth(method = "lm", color = "black") +
  labs(title = "Relationship Between Employment Level and Revision Size",
       x = "Employment (Thousands)", y = "Revision (Thousands)")


```

The scatter plot shows little correlation between employment level and revision size, as revisions remain relatively small even when employment is high. Even when employment exceeds 150,000 (thousands), revisions remain relatively small and scattered. This . The near-flat trend line also supports that this graph has a weak negative correlation and that revisions not driven by the size of the workforce.

### Statistical Inference

#### Is the average revision significantly different from zero?

```{r}
#| warning: false

obs_stat <- CES |>
  specify(response = revision) |>
  calculate(stat = "mean")

null_dist <- CES |>
  specify(response = revision) |>
  hypothesize(null = "point", mu = 0) |>
  generate(reps = 10000, type = "bootstrap") |>
  calculate(stat = "mean")

get_p_value(null_dist, obs_stat = obs_stat, direction = "two-sided")
```

The t-test indicates that the mean CES revision is significantly different from zero (p ≈ 0.0006). This suggests revisions are likely not random noise. They systematically adjust initial estimates, most likely due to incomplete survey responses and seasonal adjustments.

#### Are revisions more volatile during recessions compared to expansions?

```{r}

recession_years <- c(1980:1982, 1990:1991, 2008:2009, 2020)
CES <- CES |>
  mutate(recession = ifelse(Year %in% recession_years, "Recession", "Expansion"))

# Two-sample t-test on absolute revisions
t.test(rev_abs ~ recession, data = CES, alternative = "two.sided", na.rm = TRUE)
```

Revisions are significantly larger during recessions compared to expansions. This likely means uncertainty and volatility during downturns lead to less accurate initial estimates, requiring bigger adjustments later.

## Fact Check BLS Revisions

Here I'll fact-check two claims about CES (Current Employment Statistics) revisions and their implications for jobs data. I’ll use historical examples and one fictional claim to show how revisions work, supported by my own analysis of CES data.

### Claim 1

In mid 2009, some [commentators](https://archive.nytimes.com/economix.blogs.nytimes.com/2009/05/08/a-dreadful-yet-encouraging-jobs-report/) suggested the economy was "turning a corner" based on slowing job losses.


#### Evidence
@fig-monthemp shows an immediate decrease in employment, followed by slowing losses. This is consistent with their narrative of "encouraging signs", even though levels are week.

However, our hypothesis test confirms that revisions are larger during recessions, which explains why the 2009 adjustments were large. It takes time for the real impact of job losses to be detected. As well, @fig-scatter illustrates that revision size is not proportional to total employment. 

##### Verdict: Half True
The reporting did describe encouraging signs of a potential turning point, but revisions revealed the downturn was deeper than what earlier revisions suggested. So, having optimism on a few months' slowing losses is somewhat reasonable, but should **not** have been a strong point for the commentator.


### Claim 2 (Fictional)

A certain politician claimed, “During September revisions erase millions of jobs every year, proving that the Beauro of Labor Statistics are unreliable and not to be trusted.”

#### Evidence

@fig-revmonth shows that September has decently larger mean absolute revisions than other months. However, the revisions are in tens of thousands, and changes in overall employment numbers are usually in hundreds of thousands, meaning its actual impact on employment is much less. In @fig-heatmap, there are high revision amounts, but not all Septembers in each decade have a high revision count. In fact, out of the 10 most revised months since 1979, September only appeared ***once***.

##### Verdict: Pants on Fire
This statement heavily exaggerates ("millions of every year") and misrepresents the reason why CES data is revised. The CES data is aligned with the [Quarterly Census of Employment and Wages (QCEW)](https://www.congress.gov/crs_external_products/IF/PDF/IF13084/IF13084.1.pdf), which is more comprehensive and corrects any errors, which makes sense as September is at the end of Q3.


```{r}
library(knitr)

CES |>
  slice_max(order_by= rev_abs, n=10)|>
  mutate(employment= number(employment), big.mark=",")|>
  select(`Year and Month`= year_month, `Employment in Thousands`=employment, 
         `Revision Amount`= revision)|>
  kable(format = "html", caption = "Largest Benchmark Revisions (in thousands)")

```



------------------------------------------------------------------------

This work ©2025 by tylerml71 was initially prepared as a Mini-Project for STA 9750 at Baruch College. More details about this course can be found at [the course site](https://michael-weylandt.com/STA9750) and instructions for this assignment can be found at [MP #04](https://michael-weylandt.com/STA9750/miniprojects/mini04.html)
